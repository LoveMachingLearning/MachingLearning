Python+tensorflow学习
初识tensorflow

今天开始正式以纯0基础（高数基础为0，机器学习基础为0）直接入手深度神经网络第一天。完全照抄别人的代码进行练习。

今天学习参照的博文是：
https://blog.csdn.net/hustqb/article/details/80222055

只学习了此博文的第一部分，用于理解tensorflow的graph对象与session对象。
【graph】
直接翻译的话，graph就是图的意思，其实我今天 的理解是，这就是指运算对象——即是说:列好的算式，但还没有运算，列好的算式呢，可能是一个综合算式，记得在小学低年级时，这些综合算式会被画成计算的流程图，所以叫这些运算叫graph也是很贴切的。
在tensorflow中每一个运算都被定义为一个对象，我的理解是，一个运算对象（operation）就是一个等待计算的算式。在计算（此处即是是“运行”）之前，这个“算式”也就是一个算式，不是计算的结果。
在任何一次程序任务中，tensorflow都需要先进行graph的建构（定义），如今天照打的代码如下 ：
```
#===========================================================================================
#--从此行开始，在进行graph的搭建,我的理解是建构好要执行的各种运算，等待被执行
#下面的代码，通过tf对象的constant方法定义了一个常量const，值为float类型2.0
const=tf.constant(2.0,name="const")

#下面的代码，定义了两个变量，通过tf对象的Variable方法来定义的
b=tf.Variable(2.0,name="b")
c=tf.Variable(1.0,dtype=tf.float32,name="c")

#先定义运算operation
d=tf.add(b,c,name="d") #d在这里指的是一次加法运算，没有得到任何计算结果，它代表运算本身。(此运算对象等待真正被执行才会产生真正的计算行为)
e=tf.add(c,const,name="e")
a=tf.multiply(d,e,name="a") #这个定义的运算a，虽然其中用d,e作为了参数，但我的理解，实际上并不是使用d,e的运算结果值 ，只是使用d，e所代表的运算本身，即a在这里是一个综合算式，a代表着：(b+c) x (c+2)

#要使用上面定义好的几个变量（就是代表着运算本身的几个变量对象），还必须先由tf对象对它们进行初始化（initializer）
#下面的代码就对全体（global）变量进行了初始化,下面定义的初始化运算（init_op）其实也还是一个待执行的运算对象，也就是，下一句代码并没有对变量进行真正 的初始化 操作，只是定义 了一个可以进行初始化 操作的运算对象，等待执行运算。
init_op=tf.global_variables_initializer()
#-----到此行graph的建构就已经结束了---
#==========================================================================================
```
不过，最开始我安装的tensorflow版本是2.0.a0，结果发现2.0版本肯定是进行了重大改革，大部分代码都失效了，只好卸载2.0版本的，重新安装回1.14.1版本的。

【session】
这个单词在做网站服务器端编程时，已经接触过了，是指会话，但在tensorflow中，此处的会话应当专指真正执行对graph的计算执行会话。
得到一个会话的实例的代码我的理解是使用的是with语句：
with tf.Session() as sess: #得到一次会话
此时sess对象就是一次会话的对象。
完整执行上面已定义好的graph的会话代码如下：
```
#下面通过session会话来执行已建构的运算
with tf.Session() as sess: #得到一次会话
    #先执行初始化所有变量的运算对象
    sess.run(init_op)
    #现在才可以使用已定义的那些变量（其实是一个运算对象）
    a_out=sess.run(a) #此处的a_out不再是一个运算对象了，而是真正的运算结果
    print("建构的graph运算结果是：{}".format(a_out))

```
【tensorflow对常量、变量与基本运算的概念处理的特殊之处】
使用tf.constant()定义常量
使用tf.Variable()定义变量。
Tensorflow可以自动进行数据类型检测，比如：赋值2.0就默认为tf.float32，但最好还是显式地定义。
+−×÷都有其特殊的函数表示。
实际上，TensorFlow定义了足够多的函数来表示所有的数学运算。
如上面的代码中，+是用函数add()来表示的；乘法是用multiply()来表示的。

【今天练习的完整代码】
```
import tensorflow as tf

#===========================================================================================
#--从此行开始，在进行graph的搭建,我的理解是建构好要执行的各种运算，等待被执行
#下面的代码，通过tf对象的constant方法定义了一个常量const，值为float类型2.0
const=tf.constant(2.0,name="const")

#下面的代码，定义了两个变量，通过tf对象的Variable方法来定义的
b=tf.Variable(2.0,name="b")
c=tf.Variable(1.0,dtype=tf.float32,name="c")

#先定义运算operation
d=tf.add(b,c,name="d") #d在这里指的是一次加法运算，没有得到任何计算结果，它代表运算本身。(此运算对象等待真正被执行才会产生真正的计算行为)
e=tf.add(c,const,name="e")
a=tf.multiply(d,e,name="a") #这个定义的运算a，虽然其中用d,e作为了参数，但我的理解，实际上并不是使用d,e的运算结果值 ，只是使用d，e所代表的运算本身，即a在这里是一个综合算式，a代表着：(b+c) x (c+2)

#要使用上面定义好的几个变量（就是代表着运算本身的几个变量对象），还必须先由tf对象对它们进行初始化（initializer）
#下面的代码就对全体（global）变量进行了初始化,下面定义的初始化运算（init_op）其实也还是一个待执行的运算对象，也就是，下一句代码并没有对变量进行真正 的初始化 操作，只是定义 了一个可以进行初始化 操作的运算对象，等待执行运算。
init_op=tf.global_variables_initializer()
#-----到此行graph的建构就已经结束了---
#==========================================================================================

#下面通过session会话来执行已建构的运算
with tf.Session() as sess: #得到一次会话
    #先执行初始化所有变量的运算对象
    sess.run(init_op)
    #现在才可以使用已定义的那些变量（其实是一个运算对象）
    a_out=sess.run(a) #此处的a_out不再是一个运算对象了，而是真正的运算结果
    print("建构的graph运算结果是：{}".format(a_out))

```
执行结果：
2019-07-08 17:58:10.862276: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2建构的graph运算结果是：9.0
有一个警告提示，没有解决，估计这会对程序的执行性能有影响。
