今天继续尝试准备做入门级的人工智能——识别手写数字。今天的任务主要是加深认识，继续对每一行代码进行理解。

今天学习参照的书是：
《TensorFlow：实战Google深度学习框架（第二版）》


【argmax()函数】
摘录笔记自：https://blog.csdn.net/weixin_38145317/article/details/79650188
1.对一个一维向量
```
import numpy as np
a = np.array([3, 1, 2, 4, 6, 1])
b=np.argmax(a)#取出a中元素最大值所对应的索引，此时最大值位6，其对应的位置索引值为4，（索引值默认从0开始）
print(b)#4
这在独热表示 的 0-9数字的分类（有十个类别，分别就是0,1,2,3,4,5,6,7,8,9）中就非常方便，因为独热一般表示为如下形式：
[1,0,0,0,0,0,0,0,0,0]
这个向量（一个一维的数组，或叫列表）经过argmax一运算就得出了这个独热结果的分类（就是最终的识别结果）就是0（Index为0）
[0,1,0,0,0,0,0,0,0,0] 
这个向量（一个一维的数组，或叫列表）经过argmax一运算就得出了这个独热结果的分类（就是最终的识别结果）就是1（Index为1）

```
2.对2维向量（通常意义下的矩阵）a[][]
```
import numpy as np
a = np.array([[1, 5, 5, 2],
              [9, 6, 2, 8],
              [3, 7, 9, 1]])
b=np.argmax(a, axis=0)#对二维矩阵来讲a[0][1]会有两个索引方向，第一个方向为a[0]，默认按列方向搜索最大值
#a的第一列为1，9，3,最大值为9，所在位置为1，
#a的第一列为5，6，7,最大值为7，所在位置为2，
#此此类推，因为a有4列，所以得到的b为1行4列，
print(b)#[1 2 2 1]
 
c=np.argmax(a, axis=1)#现在按照a[0][1]中的a[1]方向，即行方向搜索最大值，
#a的第一行为1，5，5，2,最大值为5（虽然有2个5，但取第一个5所在的位置），索引值为1，
#a的第2行为9，6，2，8,最大值为9，索引值为0，
#因为a有3行，所以得到的c有3个值，即为1行3列
print(c)#[1 0 2]
```
3.对于三维矩阵a[0][1][2],情况最为复杂，但在lstm中应用最广
```
import numpy as np
a = np.array([
              [
                  [1, 5, 5, 2],
                  [9, -6, 2, 8],
                  [-3, 7, -9, 1]
              ],
 
              [
                  [-1, 7, -5, 2],
                  [9, 6, 2, 8],
                  [3, 7, 9, 1]
              ],
            [
                  [21, 6, -5, 2],
                  [9, 36, 2, 8],
                  [3, 7, 79, 1]
              ]
            ])
b=np.argmax(a, axis=0)#对于三维度矩阵，a有三个方向a[0][1][2]
#当axis=0时，是在a[0]方向上找最大值，即两个矩阵做比较，具体
#(1)比较3个矩阵的第一行，即拿[1, 5, 5, 2],
#                         [-1, 7, -5, 2],
#                         [21, 6, -5, 2],
#再比较每一列的最大值在那个矩阵中，可以看出第一列1，-2，21最大值为21，在第三个矩阵中，索引值为2
#第2列5，7，6最大值为7，在第2个矩阵中，索引值为1.....，最终得出比较结果[2 1 0 0]
#再拿出三个矩阵的第二行，按照上述方法，得出比较结果 [0 2 0 0]
#一共有三个，所以最终得到的结果b就为3行4列矩阵
print(b)
#[[0 0 0 0]
 #[0 1 0 0]
 #[1 0 1 0]]
 
c=np.argmax(a, axis=1)#对于三维度矩阵，a有三个方向a[0][1][2]
#当axis=1时，是在a[1]方向上找最大值，即在列方向比较，此时就是指在每个矩阵内部的列方向上进行比较
#(1)看第一个矩阵
                  # [1, 5, 5, 2],
                  # [9, -6, 2, 8],
                  # [-3, 7, -9, 1]
#比较每一列的最大值，可以看出第一列1，9，-3最大值为9，，索引值为1
#第2列5，-6，7最大值为7，，索引值为2
# 因此对第一个矩阵，找出索引结果为[1，2，0,1]
#再拿出2个，按照上述方法，得出比较结果 [1 0 2 1]
#一共有三个，所以最终得到的结果b就为3行4列矩阵
print(c)
#[[1 2 0 1]
 # [1 0 2 1]
 # [0 1 2 1]]
 
d=np.argmax(a, axis=2)#对于三维度矩阵，a有三个方向a[0][1][2]
#当axis=2时，是在a[2]方向上找最大值，即在行方向比较，此时就是指在每个矩阵内部的行方向上进行比较
#(1)看第一个矩阵
                  # [1, 5, 5, 2],
                  # [9, -6, 2, 8],
                  # [-3, 7, -9, 1]
#寻找第一行的最大值，可以看出第一行[1, 5, 5, 2]最大值为5，，索引值为1
#第2行[9, -6, 2, 8],最大值为9，，索引值为0
# 因此对第一个矩阵，找出行最大索引结果为[1，0，1]
#再拿出2个矩阵，按照上述方法，得出比较结果 [1 0 2 1]
#一共有三个，所以最终得到的结果d就为3行3列矩阵
print(d)
# [[1 0 1]
#  [1 0 2]
#  [0 1 2]]
###################################################################
#最后一种情况，指定矩阵a[0, -1, :]，第一个数字0代表取出第一个矩阵（从前面可以看出a有3个矩阵）为
# [1, 5, 5, 2],
# [9, -6, 2, 8],
# [-3, 7, -9, 1]
#第二个数字“-1”代表拿出倒数第一行，为
# [-3, 7, -9, 1]
#这一行的最大索引值为1
 
# ，-1，代表最后一行
m=np.argmax(a[0, -1, :])
print(m)#1
 
#h,取a的第2个矩阵
# [-1, 7, -5, 2],
# [9, 6, 2, 8],
# [3, 7, 9, 1]
#的第3行
# [3, 7, 9, 1]
#的最大值为9，索引为2
h=np.argmax(a[1, 2, :])
print(h)#2
 
g=np.argmax(a[1,:, 2])#g,取出矩阵a，第2个矩阵的第3列为-5，2，9,最大值为9，索引为2
print(g)#2
```

【今天源代码完成的批注】
```
import tensorflow as tf
import input_data

# 超参数
learning_rate = 0.5 #学习率
epochs = 10
batch_size = 100 #每次增加训练用的图片数量 

#获取图片数据集
mnist=input_data.read_data_sets("MNIST_data/",one_hot=True)
#定义一个点位节点变量表示输入层所需要的矩阵——就是一系列的训练图片集，因为每张图片的像素是28x28,所以每张图片的总像素为：784（这时每张图片都变成了一维向量，这个向量包含了784个像素的值），而二维矩阵的另一维（就是None表示那一维）是用来表示总共有多少张图片
#one_hot又称之为：独热，
'''
图像标签的独热表示
变量mnist.train.labels表示训练图像的标签，它的形状是（55000，10）。原始的图像标签是数字0-9，我们完全可以用一个数字来存储图像标签，但为什么这里每个训练标签是一个10维的向量呢？其实，这个10维的向量是原先类别号的独热（one-hot）表示。所谓独热表示，就是“一位有效编码”。我们用N维的向量来表示N个类别，每个类别占据独立的一位，任何时候独热表示中只有一位是“1”，其他都为“0”。我们可以从下面这个表格中理解独热表示：
原文：https://blog.csdn.net/ruanjianbu/article/details/87735057 
'''
x=tf.placeholder("float",[None,784])
#上一行代码中，“float”指明了此变量的数据类型，后面的列表中，指明了一个矩形区域，其中None表示任意数(就是可以接受输入任意张的图片)，在真正执行这个变量时，再设置也可。
#placeholder点位节点表示 一个等待输入的节点。
#下面是输出层所需要的点位节点，输出为one_hot模式，我的理解是，one_hot模式就是一个有十个元素的列表，每个元素都只能取0-9之间的一个整数值，用以表示输出结果（也就是神经网络猜测（预测）的结果）
y=tf.placeholder("float",[None,10])

#下面定义预设的隐藏层所需要的权重与偏置值的正态分布集合
w1=tf.Variable(tf.random_normal([784,300],stddev=0.03),name='w1')
# W是Softmax模型的参数，将一个784维的输入转换为一个300维的输出
b1=tf.Variable(tf.random_normal([300]),name="b1")
# b是又一个Softmax模型的参数，我们一般叫做“偏置项”（bias）。
#w1=tf.Variable(tf.zeros([784,300]),name='w1')
#b1=tf.Variable(tf.zeros([300]),name="b1")

#下面定义预设的输出层所需要的权重与偏置值
w2=tf.Variable(tf.random_normal([300,10],stddev=0.03),name='w2')
b2=tf.Variable(tf.random_normal([10]),name='b2')
'''
https://blog.csdn.net/dcrmg/article/details/79028043
tf.random_normal()函数用于从服从指定正太分布的数值中取出指定个数的值。
tf.random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)
    shape: 输出张量的形状，必选
    mean: 正态分布的均值，默认为0
    stddev: 正态分布的标准差，默认为1.0
    dtype: 输出的类型，默认为tf.float32
    seed: 随机数种子，是一个整数，当设置之后，每次生成的随机数都一样
    name: 操作的名称
'''
#下面构造隐藏层网络，定义运算
hidden_out=tf.add(tf.matmul(x,w1),b1) #--hidden_out=wx+b
#这儿使用了激活函数relu，激活函数的作用是，让神经网络层的加权和计算的线性化消失，变成非线性化。
hidden_out=tf.nn.relu(hidden_out)
'''
relu运算：
https://www.cnblogs.com/xh_chiang/p/9132524.html
TF-激活函数 tf.nn.relu 介绍
tf.nn.relu(features, name = None)
 这个函数的作用是计算激活函数 relu，即 max(features, 0)。即将矩阵中每行的非最大值置0。
import tensorflow as tf
a = tf.constant([-1.0, 2.0])
with tf.Session() as sess:
    b = tf.nn.relu(a)
    print sess.run(b)
以上程序输出的结果是：[0. 2.]（因为-1.0不是这一行中的最大值，所以被置为0，其实我的理解时，此时，就变成了独热表示了）
'''

#构造输出层，定义运算
# y=softmax(Wx + b)，y表示模型的输出，使用了一种保证实际图像y_和y尽量相似的模型算法softmax，总之softmax将输出层的输出结果变成了概率分布的表示
y_ = tf.nn.softmax(tf.matmul(hidden_out, w2) + b2) #加权变换并进行softmax回归，得到预测概率
#上一句中，使用hiden_out作为公式中的x，因为输出层使用隐藏层的输出结果作为输入值（一般使用x表示输入值）
'''
《TensorFlow：实战Google深度学习框架（第二版）》p76
就是说，任意事件发生的概率都在0 和1 之间，且总有某一个事件发生（ 概率的和为1 ）。
如果将分类问题中“ 一个样例属于某一个类别”看成一个概率事件，那么训练数据的正确答案就符合一个概率分布。
因为事件“ 一个样例属于不正确的类别”的概率为0,而“ 一个样例属于正确的类别”的概率为l 。
如何将神经网络前向传播得到的结果也变成概率分布呢？ 
Softmax 回归就是一个非常常用的方法。Softmax 回归本身可以作为一个学习算法来优化分类结果，但在TensorFlow 中，
 softmax回归的参数被去掉了，它只是一层额外的处理层，将神经网络的输出变成一个概率分布。
'''
#---下面进入损失函数阶段------------------
#下面求交叉熵损失——通过交叉熵来计算【预测的概率分布】（上面的softmax回归函数已经将输出层的结果变成了概率分布结果）和【真实答案的概率分布】之间的距离了。（距离值越小，就说明预测得越准确）
y_clipped = tf.clip_by_value(y_, 1e-10, 0.9999999)
cross_entropy = -tf.reduce_mean(tf.reduce_sum(y * tf.log(y_clipped) + (1 - y) * tf.log(1 - y_clipped), axis=1))
#现在cross_entropy中存放的就是损失值
'''
《TensorFlow：实战Google深度学习框架（第二版）》p77
reduce_mean用于求出平均值，axis=1说明是求矩阵中每行的平均值。
通过tf.clip_by_value 函数可以将一个张量中的数值限制在一个范围之内，这样可以避免一些运算错误（比如logO 是无效的）。
下面给出了使用tf.clip_by_value 的简单样例：
v = tf.constant([[l.0, 2.0 , 3.0], [4.0,5.0,6.0]))
print tf.clip_by_value(v, 2.5, 4.5).eval()
＃输出［［ 2.5 2.5 3.] [ 4. 4.5 4.5]]
在以上样例中可以看到，小于2.5 的数都被换成了2.5 ，而大于4.5 的数都被换成了4.5 。
------------------------------------------------------------
至此，我们得到了两个重要的Tensor：y和y_。
y_是模型的输出（即通过隐藏层计算预测后经输出层输出的预测值，是概率分布表示），y是实际的图像标签（就是它本来的正确值的概率分布），不要忘了y是独热表示的（独热表示与概率分布表示有相关吗？？）
下面我们就会根据y和y_构造损失
根据y, y_构造交叉熵损失
cross_entropy = tf.reduce_mean(-tf.reduce_sum(y * tf.log(y_)))
原文：https://blog.csdn.net/ruanjianbu/article/details/87735057 
------------------------------------------------------------------------------
《TensorFlow：实战Google深度学习框架（第二版）》p76
交叉熵损失只能计算两个概念分布之间的相距值（相似度),因此之前要使用softmax这样的回归函数将结果概率化。
交叉熵函数不是对称的C H(p, q ):;: H(q,p ）） ，
它刻画的是通过概率分布q 来表达概率分布p 的困难程度。
因为正确答案是希望得到的结果，所以当交叉熵作为神经网络的损失函数时， p 代表的是正确答案， q 代表的是预测值。
交叉脑刻画的是两个概率分布的距离，也就是说交叉熵值越小， 两个概率分布越接近。
下面将给出两个具体样例来直观地说明通过交叉熵可以判断预测答案和真实答案之间的距离。
假设有一个三分类问题，某个样例的正确答案是（ l，0，0 ） 。
某模型经过Softmax 回归之后的预测答案是（ 0.5 ,0.4 ,0.1 ），那么这个预测和正确答案之间的交叉娟为：
H((1, 0, 0), (0.5, 0.4, 0.1)) ＝-(1x log0.5 + 0 x log0.4 + 0 x log0.1)≈0.3
如果另外一个模型的预测是（0.8,0.1 , 0. l ），那么这个预测值和真实值之间的交叉熵是：
H((1, 0, 0), (0.8, 0.1, 0.1)) ＝-(1x log0.8 + 0 x log0.1 + 0 x log0.1)≈0.1
从直观上可以很容易地知道第二个预测答案要优于第一个。通过交叉熵计算得到的结果也是一致的（第二个交叉熵的值更小）
这儿的log表示 Log函数，其实就是ln（表示自然数对数函数）
对数函数log,以e(2.71828)为底，则 log0.5表示 ，求2.71828的多少次方=0.5
y * tf.log(y_)
这个运算把正确图像标签y这个一维向量各个元素的值与神经网络预测的输出结果_y这个一维向量中各个元素的值进行计算（也就是：1x log0.8 这样的运算）
然后全部元素计算之后，这两个一维向量的计算结果 是一个新的一维向量：
如
y=(1, 0, 0)
y_=(0.5, 0.4, 0.1)
则经过：
y * tf.log(y_)
运算后，得到一个新的一维向量：
(0.3,0,0)
而：
tf.reduce_sum函数将最后得到的一维向量中的全部元素进行了求和
0.3+0+0=0.3
所以最终得到一个预测值y_与正确值y之间的交叉熵损失结果为0.3
关于tf.reduce_sum看下面的博文：
https://www.jianshu.com/p/30b40b504bae
''' 

#tensorflow中有一个综合性的函数同时实现回归计算成概率分布后，再直接比较相似度：
'''
《TensorFlow：实战Google深度学习框架（第二版）》p78
因为交叉煽一般会与softmax 回归一起使用，所以TensorFlow 对这两个功能进行了统一封装，
并提供了tf.nn.softmax_cross_entropy_with_logits 函数。
比如可以直接通过以下代码来实现使用了softmax 回归之后的交叉崎损失函数：
cross entropy= tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_)
其中y_代表了原始神经网络的输出结果，而y给出了标准答案。（这两者都是概率分布的表现形式）
'''

#下面使用基础梯度下降算法构建一个优化器，（优化算法，如反向传播算法和梯度下降算法），这可以使损失函数的计算结果更小（即预测值更接近于正确值 ）
optimiser = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cross_entropy)
'''
在这儿：learning_rate是学习率，cross_entropy是损失率的值
来自链接：https://www.jianshu.com/p/200f3c4336a3
tf.train.AdamOptimizer()是利用自适应学习率的优化算法，Adam 算法和随 机梯度下降算法不同。随机梯度下降算法保持单一的学习率更新所有的参数，学习率在训练过程中并不会改变。而 Adam 算法通过计算梯度的一阶矩估计和二 阶矩估计而为不同的参数设计独立的自适应性学习率。学习率：决定每次参数更新的幅度。优化器中都需要一个叫做学习率的参数，使用时，如果学习率选择过大会出现震 荡不收敛的情况，如果学习率选择过小，会出现收敛速度慢的情况。我们可以选 个比较小的值填入，比如 0.01、0.001
-------------------------
https://www.cnblogs.com/muhe221/articles/10186156.html

'''
#定义初始化operation和准确率node
# 下面定义的是初始化所有变量的运算
init_op = tf.global_variables_initializer()

# 创建准确率节点
correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))
'''
argmax函数在寻找y与y_中的最大值所在的Index（在矩阵中按行找，即找出每行中的最大值所在的Index，因为第二个参数为1，表示 按行找，当第二个参数为0时就表示 按列找）
https://blog.csdn.net/weixin_38145317/article/details/79650188
有详细解释。
于是得到的结果是一个长度为 batch（每次迭代时从数据集中选取的图片张数，对应于输入层x定义的那个None点位，即一次输入的图片总数） 的一维数组，这个一维数组中的值就表示了每一个样例对应的数字识别结果。
因为y与y_都是batch长度x10的矩阵，因此，argmax运算后的结果就是：10个的长度长的一个一维数组，结果类似于[0,0,0,1,0,0,0,0,0,0]我感觉这就是一个独热表示，因此可以表示当前图片实际的结果值 ，如我所写的这个列表的值代表的是3类（类别）（图片识别结果为数字3）
------------------------------
tf.equal函数比较两个结果是否相等，即是说实际值 与预测值是否相等，相等就返回True,不相等就返回False
'''
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
'''
这个运算首先将一个布尔型的数值转换为实数型，然后计算平均值。这个平均值就是模型在这一组数据上的正确率。转换之后，True与False变成了1与0
tf.cast()转换类型。
'''

# 开始会话进行训练
with tf.Session() as sess:
   # 下一句代码才真正执行了初始化所有变量的运算
   sess.run(init_op)
   total_batch = int(len(mnist.train.labels) / batch_size)
   for epoch in range(epochs):
        avg_cost = 0
        for i in range(total_batch):
            batch_x, batch_y = mnist.train.next_batch(batch_size=batch_size)
            _,c = sess.run([optimiser, cross_entropy], feed_dict={x: batch_x, y: batch_y})
            avg_cost += c / total_batch
        print("Epoch:", (epoch + 1), "cost =", "{:.3f}".format(avg_cost))
   print(sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels}))


```
